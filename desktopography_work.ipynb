{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#settings for notebook\r\n",
    "from IPython.core.interactiveshell import InteractiveShell\r\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\r\n",
    "#show python version\r\n",
    "import platform\r\n",
    "platform.python_version()\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'3.8.5'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import scrapy;\r\n",
    "import bs4;\r\n",
    "import scrapydo\r\n",
    "scrapydo.setup()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import scrapy\r\n",
    "from scrapy.crawler import CrawlerProcess"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup a pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import json\r\n",
    "import requests\r\n",
    "\r\n",
    "class JsonWriterPipeline(object):\r\n",
    "\r\n",
    "    def open_spider(self, spider):\r\n",
    "        self.file = open('fileoutput.txt', 'w')\r\n",
    "\r\n",
    "    def close_spider(self, spider):\r\n",
    "        self.file.close()\r\n",
    "\r\n",
    "    def process_item(self, item, spider): \r\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\r\n",
    "        image_url = item['download'][0]\r\n",
    "        print(f'Downloading: {image_url}')\r\n",
    "        image_req = requests.get(image_url)\r\n",
    "        filename = os.path.basename(image_url)\r\n",
    "        print(f'saving to: {filename}')\r\n",
    "        image = open(f'./backgrounds/{filename}', \"wb\")\r\n",
    "        image.write(image_req.content)\r\n",
    "        image.close()\r\n",
    "        self.file.write(line)\r\n",
    "        return item"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import logging\r\n",
    "\r\n",
    "class wallpaperSpider(scrapy.Spider):\r\n",
    "\r\n",
    "    name = 'desktopography-2020'\r\n",
    "    start_urls = ['https://desktopography.net/exhibition-2020/']\r\n",
    "    custom_settings = {\r\n",
    "        'LOG_LEVEL': logging.WARNING,\r\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\r\n",
    "       \r\n",
    "    }\r\n",
    "\r\n",
    "    def parse(self, response):\r\n",
    "        # yield {\r\n",
    "        #     'title': response.css('title').extract(),\r\n",
    "        #     'url': response.url,\r\n",
    "        #     #'entries': response.css('div.portfolio-item').extract(),\r\n",
    "        # }\r\n",
    "        for entry in response.css('div.portfolio-item a.overlay-background::attr(href)'):\r\n",
    "            yield response.follow(url=entry.get(), callback=self.parse_downloads)\r\n",
    "    \r\n",
    "    def parse_downloads(self, response):\r\n",
    "        yield {\r\n",
    "            'download': response.xpath(\"//a[text()=\\'3840x2160\\']/@href\").extract()\r\n",
    "        }\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\r\n",
    "#Run the crawler\r\n",
    "scrapydo.run_spider(wallpaperSpider, settings={\r\n",
    "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\r\n",
    "})"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading: https://desktopography.net/wp-content/uploads/bfi_thumb/RhayvenJonesTwisted-3bj8m7vlhd5wsblcnioohs.jpg\n",
      "saving to: RhayvenJonesTwisted-3bj8m7vlhd5wsblcnioohs.jpg\n",
      "Downloading: https://desktopography.net/wp-content/uploads/bfi_thumb/Michal_Krawczyk_Happines-3bjbqmeuq0peino05zr9j4.jpg\n",
      "saving to: Michal_Krawczyk_Happines-3bjbqmeuq0peino05zr9j4.jpg\n",
      "Downloading: https://desktopography.net/wp-content/uploads/bfi_thumb/dt2020_flatlogo-sara-lunatiq-3bjbya7nq8nqp53mmekidc.jpg\n",
      "saving to: dt2020_flatlogo-sara-lunatiq-3bjbya7nq8nqp53mmekidc.jpg\n",
      "Downloading: https://desktopography.net/wp-content/uploads/bfi_thumb/hunter_final-2-3bjeo928orodytwh22z5ds.jpg\n",
      "saving to: hunter_final-2-3bjeo928orodytwh22z5ds.jpg\n",
      "Downloading: https://desktopography.net/wp-content/uploads/bfi_thumb/Nikola-Angelkoski-Covenant-copy-3bj8mkfxmmgqp68j6568zk.jpg\n",
      "saving to: Nikola-Angelkoski-Covenant-copy-3bj8mkfxmmgqp68j6568zk.jpg\n",
      "Downloading: https://desktopography.net/wp-content/uploads/bfi_thumb/Up_the_Sky-3bj8nc32qzq63ugbwpui2o.jpg\n",
      "saving to: Up_the_Sky-3bj8nc32qzq63ugbwpui2o.jpg\n",
      "Downloading: https://desktopography.net/wp-content/uploads/bfi_thumb/LEVITATE-3bjbxdaj9l0ekfj7pg4pvk.jpg\n",
      "saving to: LEVITATE-3bjbxdaj9l0ekfj7pg4pvk.jpg\n",
      "Downloading: https://desktopography.net/wp-content/uploads/bfi_thumb/Planets_Desk-3bjbxo3jmqulklq6ty13wg.jpg\n",
      "saving to: Planets_Desk-3bjbxo3jmqulklq6ty13wg.jpg\n",
      "Downloading: https://desktopography.net/wp-content/uploads/bfi_thumb/FOREST_warped-3bjbxxe9weaj86ypc1pmo0.jpg\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
   }
  },
  "orig_nbformat": 2,
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}